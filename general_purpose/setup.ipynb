{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "setup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da6YfLPPN9yG"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from scipy import stats\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def connect_kaggle():\n",
        "  !pip install -q kaggle\n",
        "  files.upload()\n",
        "  !mkdir ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "  !kaggle datasets list\n",
        "\n",
        "def download_kaggle(name):\n",
        "  os.system(f\"kaggle competitions download -c '{name}' \")\n",
        "\n",
        "def submit_kaggle(title, filename, message=\"No message specified\"):\n",
        "    os.system(f\"kaggle competitions submit -c '{title}' -f '{filename}' -m '{message}'\")\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "def plot_precision_recall_vs_threshold(true_label, pred, ax=None):\n",
        "    precisions, recalls, thresholds = precision_recall_curve(true_label, pred)\n",
        "    if ax is None:\n",
        "      ax = plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "      ax.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "      ax.set_xlabel(\"Threshold\", fontsize=16)\n",
        "      ax.legend(loc=\"upper left\", fontsize=16)\n",
        "      ax.set_ylim([0, 1])\n",
        "\n",
        "    else:\n",
        "      ax.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "      ax.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "      ax.set_xlabel(\"Threshold\", fontsize=16)\n",
        "      ax.legend(loc=\"upper left\", fontsize=16)\n",
        "      ax.set_ylim([0, 1])\n",
        "    \n",
        "    return ax\n",
        "\n",
        "def plot_roc_curve(true_label, pred_score, label=None, ax=None):\n",
        "    fpr, tpr, threshold = roc_curve(true_label, pred_score)\n",
        "    if ax is None:\n",
        "      plt.plot(fpr, tpr, linewidth=2)\n",
        "      plt.plot([0, 1], [0, 1], 'k--')\n",
        "      plt.axis([0, 1, 0, 1])\n",
        "      plt.xlabel('False Positive Rate', fontsize=16)\n",
        "      plt.ylabel('True Positive Rate', fontsize=16)\n",
        "      return plt.gca()\n",
        "\n",
        "    else:\n",
        "      ax.plot(fpr, tpr, linewidth=2)\n",
        "      ax.plot([0, 1], [0, 1], 'k--')\n",
        "      ax.axis([0, 1, 0, 1])\n",
        "      ax.set_xlabel('False Positive Rate', fontsize=16)\n",
        "      ax.set_ylabel('True Positive Rate', fontsize=16)\n",
        "      return ax\n",
        "\n",
        "def display_score(score):\n",
        "  print(\"Individual score: \", score)\n",
        "  print(\"Mean: \", score.mean())\n",
        "  print(\"Standard deviation: \", score.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW8voxR9e6bo"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, precision_score, \\\n",
        "                            recall_score, f1_score, precision_recall_curve, \\\n",
        "                            roc_curve, roc_auc_score\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, num_label, cv=3, proba=False):\n",
        "  pred = cross_val_predict(model, X_train, y_train, cv=cv)\n",
        "  pred_confusion = confusion_matrix(y_train, pred)\n",
        "  index = [i for i in range(num_label)]\n",
        "  df_conf = pd.DataFrame(pred_confusion, columns=index, index=index)\n",
        "\n",
        "  if proba:\n",
        "    pred_proba = cross_val_predict(model, X_train, y_train, cv=cv, method='decision_function')\n",
        "\n",
        "  print(\"Metrics \")\n",
        "  print(\"-------\")\n",
        "  print(\"Recall: \", recall_score(y_train, pred))\n",
        "  print(\"Precision: \", precision_score(y_train, pred))\n",
        "  print(\"F1_score: \", f1_score(y_train, pred))\n",
        "  print(\"ROC_AUC Score: \", roc_auc_score(y_train, pred_proba) if proba else \"\")\n",
        "  \n",
        "  print(\"Cross validation score\")\n",
        "  print(\"----------------------\")\n",
        "  display_score(cross_val_score(model, X_train, y_train, cv=cv))\n",
        "\n",
        "  ax1= plt.subplot(2, 2, 1)\n",
        "  sns.heatmap(df_conf, annot=True, ax=ax1)\n",
        "  ax1.set_xlabel(\"Model prediction\")\n",
        "  ax1.set_ylabel(\"True prediction\")\n",
        "  ax1.set_title(\"Confusion matrix\")\n",
        "\n",
        "  if proba:\n",
        "    ax2 = plt.subplot(2, 2, 2)\n",
        "    plot_precision_recall_vs_threshold(y_train, pred_proba, ax=ax2)\n",
        "\n",
        "    ax3 = plt.subplot(2, 1, 2)\n",
        "    plot_roc_curve(y_train, pred_proba, label=\"ROC_curve\", ax=ax3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0VooSkzfYlX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def preprocess_data(data, drop=[], cat_col=[], label=[], test_size = 0.2):\n",
        "  '''\n",
        "  Standardize the numerical data,\n",
        "  and split the data into training and testing dataset.\n",
        "  '''\n",
        "  data = data.drop(drop, axis=1)\n",
        "  num_col = list(set(data.columns) - set(cat_col) - set(label))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data.drop(label, axis=1), \n",
        "                                                      data[label],\n",
        "                                                      test_size=test_size)\n",
        "  std_scaler = StandardScaler()\n",
        "  pipeline = ColumnTransformer([\n",
        "                       (\"std_scaler\", std_scaler, num_col)\n",
        "  ], remainder=\"passthrough\")\n",
        "  X_train = pipeline.fit_transform(X_train)\n",
        "  X_test = pipeline.transform(X_test)\n",
        "  return (X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YDEFvV0O8XU"
      },
      "source": [
        "class Fill_Na(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, filler):\n",
        "    self.filler = filler\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    if type(X) == np.ndarray:\n",
        "      X = np.nan_to_num(X, nan=self.filler)\n",
        "\n",
        "    elif type(X) == pd.DataFrame:\n",
        "      X = X.fillna(self.filler)\n",
        "    \n",
        "    else:\n",
        "      raise TypeError(\"Unknown type of X\")\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "class Drop_Col(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, col_list):\n",
        "    self.col_list = col_list\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    if type(X) != pd.DataFrame:\n",
        "      raise TypeError(f\"Drop Col should take a DataFrame argument, not {type(X)}\")\n",
        "    \n",
        "    else:\n",
        "      return X.drop(self.col_list, axis=1)\n",
        "\n",
        "class Impute(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, col, strategy, reference=None):\n",
        "    self.col = col\n",
        "    self.strategy = strategy\n",
        "    self.reference = reference\n",
        "    self.imputer = SimpleImputer(strategy=self.strategy)\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    if self.reference is None:\n",
        "      self.imputer.fit(X[[self.col]])\n",
        "    \n",
        "    else:\n",
        "      self.imputer.fit(self.reference[[self.col]])\n",
        "\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X):\n",
        "    if type(X) != pd.DataFrame:\n",
        "      raise TypeError(f\"Drop Col should take a DataFrame argument, not {type(X)}\")\n",
        "    \n",
        "    else:\n",
        "      X[self.col] = self.imputer.transform(X[[self.col]])\n",
        "      \n",
        "      return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkwhdV4d9Ubu"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "def unzip_tar(file_path, target='.'):\n",
        "  tgz = tarfile.open(file_path)\n",
        "  tgz.extractall(path=target)\n",
        "  tgz.close()\n",
        "\n",
        "def unzip(file_path, target='.'):\n",
        "  with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c9aiB1HWwT7"
      },
      "source": [
        "import time\n",
        "\n",
        "def generate_dir(name=\"Untitled\", date=False):\n",
        "  if date:\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(TENSORBOARD_DIR, run_id)\n",
        "\n",
        "  else:\n",
        "    return os.path.join(TENSORBOARD_DIR, name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yspRLV16XFWd"
      },
      "source": [
        "def upload_files(dataframe=False, xlsx=False):\n",
        "  uploaded = files.upload()\n",
        "  if dataframe:\n",
        "    payload = []\n",
        "    for i in uploaded.keys():\n",
        "      payload.append(pd.read_csv(io.BytesIO(uploaded[i])))\n",
        "    \n",
        "    return payload\n",
        "\n",
        "  else:\n",
        "    return uploaded\n",
        "\n",
        "def locate_outlier(df, columns, zscore_threshold, any=True, exclude=False):\n",
        "  mask_include = np.abs(stats.zscore(df[columns])) > zscore_threshold\n",
        "  mask_exclude = np.abs(stats.zscore(df[columns])) < zscore_threshold\n",
        "\n",
        "  if any:\n",
        "    if exclude:\n",
        "      return df[mask_exclude.any(axis=1)]\n",
        "    else:\n",
        "      df = df[mask_include.any(axis=1)]\n",
        "      outlier_field = pd.DataFrame(mask_include, columns=columns)\n",
        "      outlier_field = outlier_field.apply(lambda x: x.replace(True, x.name).replace(False, \"\"))\n",
        "      outlier_field = outlier_field.apply(lambda x: x.str.cat(sep=''), axis=1)\n",
        "      outlier_field = outlier_field.replace(\"\", np.nan).dropna()\n",
        "      outlier_field.rename(\"Outlier_field\", inplace=True)\n",
        "      assert df.index.equals(outlier_field.index)\n",
        "      return pd.concat([df, outlier_field], axis=1)\n",
        "  \n",
        "  else:\n",
        "    if exclude:\n",
        "      return df[mask_exclude.all(axis=1)]\n",
        "\n",
        "    else:\n",
        "      df = df[mask_include.all(axis=1)]\n",
        "      outlier_field = pd.DataFrame(mask_include, columns=columns)\n",
        "      outlier_field = outlier_field.apply(lambda x: x.replace(True, x.name).replace(False, \"\"))\n",
        "      outlier_field = outlier_field.apply(lambda x: x.str.cat(sep=''), axis=1)\n",
        "      outlier_field = outlier_field.replace(\"\", np.nan).dropna()\n",
        "      outlier_field.rename(\"Outlier_field\", inplace=True)\n",
        "      assert df.index.equals(outlier_field.index)\n",
        "      return pd.concat([df, outlier_field], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYl5ExxV8vcW"
      },
      "source": [
        "import ipywidgets as widget\n",
        "\n",
        "class BasicUI(object):\n",
        "  def __init__(self, tracked_df):\n",
        "    self._tracked_df = tracked_df\n",
        "    self._df_select = widget.Dropdown(description=\"DataFrame\", options=tracked_df)\n",
        "    self._view_option = widget.RadioButtons(description=\"View\", options=[\"general\", \"info\", \"describe\", \"value_counts\"])\n",
        "    self._max_row_option = widget.IntText(description=\"Max rows\", value=-1)\n",
        "    self._max_column_option = widget.IntText(description=\"Max columns\", value=-1)\n",
        "    self._max_colwidth_option = widget.IntText(description=\"Max col width\", value=-1)\n",
        "\n",
        "  def df_info(self, df, option):\n",
        "    df = globals()[df]\n",
        "    if option == \"info\":\n",
        "      display(df.info())\n",
        "    \n",
        "    elif option == \"describe\":\n",
        "      display(df.describe())\n",
        "    \n",
        "    elif option == \"value_counts\":\n",
        "      display(df.apply(lambda x: x.value_counts()).unstack().dropna().T)\n",
        "    \n",
        "    elif option == \"general\":\n",
        "      display(df)\n",
        "    \n",
        "  def set_max_rows(self, n):\n",
        "    if n == -1:\n",
        "      pd.reset_option(\"max_rows\")\n",
        "    \n",
        "    else:\n",
        "      pd.set_option(\"max_rows\", n)\n",
        "\n",
        "  def set_max_columns(self, n):\n",
        "    if n == -1:\n",
        "      pd.reset_option(\"max_column\")\n",
        "    \n",
        "    else:\n",
        "      pd.set_option(\"max_column\", n)\n",
        "  \n",
        "  def set_max_colwidth(self, n):\n",
        "    if n == -1:\n",
        "      pd.reset_option(\"max_colwidth\")\n",
        "    \n",
        "    else:\n",
        "      pd.set_option(\"max_colwidth\", n)\n",
        "  \n",
        "  def run(self):\n",
        "    general_utilities = widget.interactive(self.df_info, df=self._df_select, option=self._view_option)\n",
        "    max_row = widget.interactive(self.set_max_rows, n=self._max_row_option)\n",
        "    max_col = widget.interactive(self.set_max_columns, n=self._max_column_option)\n",
        "    max_colwidth = widget.interactive(self.set_max_colwidth, n=self._max_colwidth_option)\n",
        "    general_option = widget.VBox([max_col, max_row, max_colwidth])\n",
        "    \n",
        "    main_option = widget.Tab([general_utilities, general_option], \n",
        "                               titles=(\"Utilities\", \"Option\"))\n",
        "    display(main_option)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExXTh7eJqj1K"
      },
      "source": [
        "def plotter(f):\n",
        "  def plotter_function(*args, figsize=(12, 12), title='Big title', **kwargs):\n",
        "    plt.figure(figsize=figsize, tight_layout=True)\n",
        "    f(*args, **kwargs)\n",
        "    figure = plt.gcf()\n",
        "    figure.suptitle(title, fontsize=16, y=1.05)\n",
        "  return plotter_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVmF2anmo6hP"
      },
      "source": [
        "@plotter\n",
        "def plot_each_col(data, col_list, n_col, plot_type, x=None, **kwargs):\n",
        "  n_row = len(col_list) // n_col + 1\n",
        "  for i, col in enumerate(col_list):\n",
        "    ax = plt.subplot(n_row, n_col, i + 1)\n",
        "    if plot_type == \"hist\":\n",
        "      sns.histplot(data=data, x=col, hue=LABEL, multiple=\"stack\", **kwargs)\n",
        "    \n",
        "    elif plot_type == \"bar\":\n",
        "      sns.barplot(data=data, x=col, y=LABEL, **kwargs)\n",
        "\n",
        "    elif plot_type == \"count\":\n",
        "      sns.countplot(data=data, x=col, **kwargs)\n",
        "\n",
        "    elif plot_type == \"box\":\n",
        "      sns.boxplot(data=data, x=col, **kwargs)\n",
        "    \n",
        "    elif plot_type == \"line\":\n",
        "      if x:\n",
        "        sns.lineplot(data=data, x=x, y=col, ax=ax, **kwargs)\n",
        "\n",
        "      else:\n",
        "        sns.lineplot(data=data, x=data.index, y=col, ax=ax, **kwargs)\n",
        "\n",
        "    else:\n",
        "      raise ValueError(f\"Invalid plot_type argument: {plot_type}\")\n",
        "\n",
        "    ax.set_title(f\"Distribution of {col}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}